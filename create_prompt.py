import os
import cv2
import torch
import pandas as pd
import numpy as np
from ultralytics import YOLO

# ========== é…ç½® ==========
video_path = "/home/itaer2/zxy/cataract/external/datasets/testvideo/video4.mpg"
yolo_weights = "/home/itaer2/zxy/ultralytics-main-2/runs/detect/cataract/weights/best.pt"
stage_csv = "/home/itaer2/zxy/cataract/external/datasets/Annotations/videos/videos2/video4.csv"
output_csv = "./auto_sam2_box_prompts_external.csv"
preview_dir = "./preview_frames_external"  # å¸§é¢„è§ˆä¿å­˜è·¯å¾„
os.makedirs(preview_dir, exist_ok=True)

fps = 25  # è§†é¢‘å¸§ç‡
conf_thres = 0.4  # YOLOæ£€æµ‹é˜ˆå€¼

# ========== 1. åŠ è½½æ¨¡å‹ä¸é˜¶æ®µè¡¨ ==========
print("ğŸš€ æ­£åœ¨åŠ è½½YOLOæ¨¡å‹...")
model = YOLO(yolo_weights)
df = pd.read_csv(stage_csv)

cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    raise RuntimeError(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
print(f"ğŸ¥ è§†é¢‘åˆ†è¾¨ç‡: {w}x{h}")

# ========== 2. è‡ªåŠ¨ç”Ÿæˆ Box Prompts ==========
records = []  # ä¿å­˜æ‰€æœ‰ç»“æœ

for idx, row in df.iterrows():
    start_sec, end_sec, caption = row["start_sec"], row["end_sec"], row["caption"]
    clip_idx = idx
    print(f"\nğŸ©º å¤„ç†é˜¶æ®µ {clip_idx}: {caption}")

    # ä¸‰å¸§é‡‡æ ·ï¼šèµ·å§‹ / ä¸­é—´ / ç»“æŸ
    frame_times = np.linspace(start_sec, end_sec, num=3)

    for sec in frame_times:
        frame_idx = int(sec * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            print(f"âš ï¸ æ— æ³•è¯»å– {sec:.2f}s çš„å¸§ï¼Œè·³è¿‡ã€‚")
            continue

        # YOLO æ£€æµ‹
        results = model(frame)
        boxes = results[0].boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
        confs = results[0].boxes.conf.cpu().numpy()
        cls_ids = results[0].boxes.cls.cpu().numpy()

        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        mask = confs > conf_thres
        boxes = boxes[mask]
        cls_ids = cls_ids[mask]

        if len(boxes) == 0:
            print(f"âŒ é˜¶æ®µ [{caption}] å¸§ {frame_idx} æ— æ£€æµ‹ç»“æœã€‚")
            continue

        # ç»˜åˆ¶æ£€æµ‹æ¡†ç”¨äºé¢„è§ˆ
        preview_frame = frame.copy()
        for i, (box, cls_id) in enumerate(zip(boxes, cls_ids)):
            x1, y1, x2, y2 = box.astype(int)
            cv2.rectangle(preview_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(preview_frame, f"cls{int(cls_id)}", (x1, y1 - 8),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            # ä¿å­˜ CSV è®°å½•
            records.append({
                "clip_idx": clip_idx,
                "frame_idx": frame_idx,
                "x1": round(float(x1), 2),
                "y1": round(float(y1), 2),
                "x2": round(float(x2), 2),
                "y2": round(float(y2), 2),
                "label": 1,  # SAM2 é€šå¸¸ 1 è¡¨ç¤ºæ­£æ ·æœ¬
                "caption": caption
            })

        # ä¿å­˜é¢„è§ˆå›¾
        preview_path = os.path.join(preview_dir, f"clip{clip_idx}_frame{frame_idx}.jpg")
        cv2.imwrite(preview_path, preview_frame)
        print(f"ğŸ–¼ï¸ å·²ä¿å­˜æ£€æµ‹é¢„è§ˆå¸§: {preview_path}")

cap.release()

# ========== 3. ä¿å­˜ä¸º CSV ==========
out_df = pd.DataFrame(records)
out_df.to_csv(output_csv, index=False)
print(f"\nğŸ’¾ å·²ä¿å­˜ CSV: {output_csv}")
print(f"ğŸ“Š å…±ç”Ÿæˆ {len(out_df)} æ¡æ£€æµ‹æç¤ºæ¡†ã€‚")
print(f"ğŸ–¼ï¸ é¢„è§ˆå›¾æ–‡ä»¶å¤¹: {preview_dir}")

# ========== 4. ç¤ºä¾‹ï¼šSAM2åŠ è½½æ–¹å¼ ==========
# df = pd.read_csv(output_csv)
# for _, row in df.iterrows():
#     predictor.add_new_points_or_box(
#         frame_idx=int(row["frame_idx"]),
#         obj_id=2,
#         box=np.array([row[["x1","y1","x2","y2"]].values], dtype=np.float32)
#     )
