import torch
from torch.utils.data import DataLoader, Dataset
from transformers import BlipProcessor, BlipForConditionalGeneration, get_scheduler
from tqdm import tqdm
import os
import pandas as pd
from PIL import Image
import warnings
import sys
from datetime import datetime
warnings.filterwarnings("ignore")

# ================ è¯„ä¼°æŒ‡æ ‡é…ç½® ================
sys.path.append("/home/itaer2/zxy/shixi/code/main/blip/pycocoevalcap-master")
from bleu.bleu import Bleu
from rouge.rouge import Rouge
from meteor.meteor import Meteor
from cider.cider import Cider

# ================ 1. é…ç½®å‚æ•° ================
config = {
    "train_csv": "/home/itaer2/zxy/cataract/datasets/split/split3/train.csv",
    "val_csv": "/home/itaer2/zxy/cataract/datasets/split/split3/val.csv",
    "test_csv": "/home/itaer2/zxy/cataract/datasets/split/split3/test.csv",
    "images_root": "/home/itaer2/zxy/cataract/datasets/images/frames3",

    "output_dir": "/home/itaer2/zxy/cataract/code/output/train3",
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "epochs": 30,
    "batch_size": 2,
    "accumulation_steps": 8,
    "learning_rate": 3e-5,
    "weight_decay": 1e-5,                                    
    "warmup_ratio": 0.1,
    "max_caption_length": 50,
    "use_fp16": True,
    "num_workers": 4,

    "num_beams": 3,
    "early_stopping": True,

    "image_extension": ".jpg",
    "skip_invalid_image": True
}
os.makedirs(config["output_dir"], exist_ok=True)
print(f"ğŸ“Œ è®­ç»ƒé…ç½®: è®¾å¤‡={config['device']}, æ€»æœ‰æ•ˆæ‰¹æ¬¡={config['batch_size']*config['accumulation_steps']}")

# ================ 2. æ„å»ºå›¾ç‰‡è·¯å¾„æ˜ å°„ ================
def build_image_path_map(root_dir):
    image_map = {}
    print(f"ğŸ” æ­£åœ¨æ‰«æå›¾ç‰‡æ ¹ç›®å½•åŠå­æ–‡ä»¶å¤¹: {root_dir}")
    for dirpath, _, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.endswith(config["image_extension"]):
                image_id = os.path.splitext(filename)[0]
                if image_id not in image_map:
                    image_map[image_id] = os.path.join(dirpath, filename)
                    if len(image_map) <= 5:
                        print(f"   æ˜ å°„ç¤ºä¾‹: image_id={image_id} â†’ è·¯å¾„={os.path.join(dirpath, filename)}")
    print(f"âœ… å›¾ç‰‡è·¯å¾„æ˜ å°„æ„å»ºå®Œæˆï¼Œå…±å‘ç° {len(image_map)} å¼ å›¾ç‰‡")
    return image_map

image_path_map = build_image_path_map(config["images_root"])

# ================ 3. æ•°æ®æ ¡éªŒ ================
def validate_data():
    print("\nğŸ” å¼€å§‹æ•°æ®æ ¡éªŒ...")
    valid = True
    for name, path in [("è®­ç»ƒé›†", config["train_csv"]),
                      ("éªŒè¯é›†", config["val_csv"]),
                      ("æµ‹è¯•é›†", config["test_csv"])]:
        if not os.path.exists(path):
            print(f"âŒ {name}æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            valid = False
        else:
            df = pd.read_csv(path)
            print(f"âœ… {name}æ ‡æ³¨æ–‡ä»¶æ­£å¸¸ï¼ˆ{len(df)}è¡Œï¼‰: {path}")
            required_cols = ["image_id", "frame", "caption"]
            if not all(col in df.columns for col in required_cols):
                print(f"âŒ {name}æ ‡æ³¨æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼Œéœ€åŒ…å«: {required_cols}")
                valid = False
    if len(image_path_map) == 0:
        print(f"âŒ æœªåœ¨ {config['images_root']} ä¸­æ‰¾åˆ°ä»»ä½•{config['image_extension']}å›¾ç‰‡")
        valid = False
    if valid and os.path.exists(config["train_csv"]):
        train_df = pd.read_csv(config["train_csv"])
        sample_ids = train_df["image_id"].head(5).tolist()
        for image_id in sample_ids:
            if image_id in image_path_map:
                print(f"âœ… image_id={image_id} æ‰¾åˆ°å¯¹åº”å›¾ç‰‡: {image_path_map[image_id]}")
            else:
                print(f"âŒ image_id={image_id} æœªæ‰¾åˆ°å¯¹åº”å›¾ç‰‡")
                valid = False
    if not valid:
        print("\nâŒ æ•°æ®æ ¡éªŒå¤±è´¥")
        sys.exit(1)
    print("âœ… æ•°æ®æ ¡éªŒé€šè¿‡ï¼")

validate_data()

# ================ 4. æ•°æ®é›†ç±» ================
class CataractDataset(Dataset):
    def __init__(self, csv_path, image_map, processor, config):
        self.csv_path = csv_path
        self.df = pd.read_csv(csv_path)
        self.image_map = image_map
        self.processor = processor
        self.config = config
        self.clean_data()
        self.check_validity()
        print(f"âœ… åŠ è½½ {os.path.basename(csv_path)}: {len(self.df)} æ¡æœ‰æ•ˆæ•°æ®")

    def clean_data(self):
        self.df = self.df[["image_id", "frame", "caption"]].dropna().reset_index(drop=True)
        original_count = len(self.df)
        self.df = self.df[self.df["image_id"].isin(self.image_map.keys())].reset_index(drop=True)
        print(f"   è¿‡æ»¤æ— æ•ˆimage_id: åŸå§‹{original_count}æ¡ â†’ ä¿ç•™{len(self.df)}æ¡")

    def check_validity(self):
        if len(self.df) == 0:
            raise ValueError(f"æ•°æ®é›† {os.path.basename(self.csv_path)} æ— æœ‰æ•ˆæ•°æ®ï¼")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        try:
            row = self.df.iloc[idx]
            image_id = str(row["image_id"])
            caption = str(row["caption"]).strip()
            image_path = self.image_map[image_id]
            with Image.open(image_path) as img:
                image = img.convert("RGB")
            encoding = self.processor(
                images=image,
                text=caption,
                padding="max_length",
                truncation=True,
                max_length=self.config["max_caption_length"],
                return_tensors="pt"
            )
            data = {k: v.squeeze() for k, v in encoding.items()}
            data["image_id"] = image_id
            return data
        except Exception as e:
            if self.config.get("skip_invalid_image", True):
                return self.__getitem__((idx + 1) % len(self))
            else:
                raise

# ================ 5. æ¨¡å‹ä¸æ•°æ®åŠ è½½ ================
processor = BlipProcessor.from_pretrained(
    "/home/itaer2/zxy/shixi/code/Salesforce/blip-image-captioning-base"
)
model = BlipForConditionalGeneration.from_pretrained(
    "/home/itaer2/zxy/shixi/code/Salesforce/blip-image-captioning-base"
).to(config["device"])

train_dataset = CataractDataset(config["train_csv"], image_path_map, processor, config)
val_dataset = CataractDataset(config["val_csv"], image_path_map, processor, config)
test_dataset = CataractDataset(config["test_csv"], image_path_map, processor, config) if os.path.exists(config["test_csv"]) else None

train_loader = DataLoader(train_dataset, batch_size=config["batch_size"], shuffle=True, num_workers=config["num_workers"], pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=config["batch_size"], shuffle=False, num_workers=config["num_workers"], pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=config["batch_size"], shuffle=False, num_workers=config["num_workers"], pin_memory=True) if test_dataset else None

optimizer = torch.optim.AdamW(model.parameters(), lr=config["learning_rate"], weight_decay=config["weight_decay"])
num_training_steps = config["epochs"] * len(train_loader) // config["accumulation_steps"]
num_warmup_steps = int(num_training_steps * config["warmup_ratio"])
lr_scheduler = get_scheduler("linear", optimizer=optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)

# ================ 6. æŒ‡æ ‡è®¡ç®— ================
class MetricsCalculator:
    def __init__(self):
        self.bleu_scorer = Bleu(4)
        self.rouge_scorer = Rouge()
        self.meteor_scorer = Meteor()
        self.cider_scorer = Cider()
    def compute(self, predictions, references):
        gts = {i: [ref] for i, ref in enumerate(references)}
        res = {i: [pred] for i, pred in enumerate(predictions)}
        bleu_scores, _ = self.bleu_scorer.compute_score(gts, res)
        rouge_score, _ = self.rouge_scorer.compute_score(gts, res)
        meteor_score, _ = self.meteor_scorer.compute_score(gts, res)
        cider_score, _ = self.cider_scorer.compute_score(gts, res)
        return {"BLEU-1": bleu_scores[0], "BLEU-2": bleu_scores[1],
                "BLEU-3": bleu_scores[2], "BLEU-4": bleu_scores[3],
                "ROUGE-L": rouge_score, "METEOR": meteor_score, "CIDEr": cider_score}
metrics_calculator = MetricsCalculator()

# ================ 7. è®­ç»ƒå’Œè¯„ä¼°å‡½æ•° ================
def _move_batch_to_device(batch, device):
    moved = {}
    for k, v in batch.items():
        if k == "image_id":
            moved[k] = v
            continue
        if isinstance(v, list):
            moved[k] = v
            continue
        try:
            moved[k] = v.to(device)
        except:
            moved[k] = v
    return moved

def train_one_epoch(epoch):
    model.train()
    total_loss = 0.0
    optimizer.zero_grad()
    for step, batch in enumerate(tqdm(train_loader, desc=f"Epoch {epoch:2d} [Train]")):
        batch = _move_batch_to_device(batch, config["device"])
        if config["use_fp16"]:
            with torch.cuda.amp.autocast():
                outputs = model(**{k:v for k,v in batch.items() if k!='image_id'}, labels=batch["input_ids"])
                loss = outputs.loss / config["accumulation_steps"]
            scaler.scale(loss).backward()
        else:
            outputs = model(**{k:v for k,v in batch.items() if k!='image_id'}, labels=batch["input_ids"])
            loss = outputs.loss / config["accumulation_steps"]
            loss.backward()
        if (step + 1) % config["accumulation_steps"] == 0:
            if config["use_fp16"]:
                scaler.step(optimizer)
                scaler.update()
            else:
                optimizer.step()
            lr_scheduler.step()
            optimizer.zero_grad()
        total_loss += loss.item() * config["accumulation_steps"]
    return total_loss / len(train_loader)

def evaluate_model(dataloader, split_name, save_results_path=None):
    model.eval()
    total_loss = 0.0
    all_preds, all_refs, all_image_ids = [], [], []
    with torch.no_grad():
        for batch in tqdm(dataloader, desc=f"[{split_name}] è¯„ä¼°ä¸­"):
            batch = _move_batch_to_device(batch, config["device"])
            outputs = model(**{k:v for k,v in batch.items() if k!='image_id'}, labels=batch["input_ids"])
            total_loss += outputs.loss.item()
            generated_ids = model.generate(
                pixel_values=batch["pixel_values"],
                max_length=config["max_caption_length"],
                num_beams=config["num_beams"],
                early_stopping=config["early_stopping"]
            )
            preds = processor.batch_decode(generated_ids, skip_special_tokens=True)
            refs = processor.batch_decode(batch["input_ids"], skip_special_tokens=True)
            ids = batch.get("image_id", [])
            if not isinstance(ids, (list, tuple)):
                ids = [ids]
            n = min(len(preds), len(refs), len(ids))
            preds, refs, ids = preds[:n], refs[:n], ids[:n]
            all_preds.extend(preds)
            all_refs.extend(refs)
            all_image_ids.extend(ids)
    metrics = metrics_calculator.compute(all_preds, all_refs) if len(all_preds) > 0 else {}
    avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else float("nan")
    print(f"\n{split_name}é›†ç”Ÿæˆç¤ºä¾‹:")
    for i in range(min(3, len(all_preds))):
        print(f"image_id: {all_image_ids[i]}")
        print(f"çœŸå®: {all_refs[i]}")
        print(f"é¢„æµ‹: {all_preds[i]}")
        print("-"*80)
    if save_results_path is not None:
        import csv
        os.makedirs(os.path.dirname(save_results_path), exist_ok=True)
        with open(save_results_path, "w", newline="", encoding="utf-8") as csvf:
            writer = csv.writer(csvf)
            writer.writerow(["image_id", "reference", "prediction"])
            for iid, ref, pred in zip(all_image_ids, all_refs, all_preds):
                writer.writerow([iid, ref, pred])
        print(f"âœ… å·²ä¿å­˜ {split_name} é€æ ·æœ¬é¢„æµ‹åˆ°: {save_results_path}")
    return avg_loss, metrics, all_preds, all_refs, all_image_ids

# ================ 8. è®­ç»ƒä¸»å¾ªç¯ ================
# ===================== 8. è®­ç»ƒä¸»å¾ªç¯ï¼ˆä»…ä¿å­˜BLEU-4æœ€ä¼˜æ¨¡å‹ï¼‰ =====================
scaler = torch.cuda.amp.GradScaler() if config["use_fp16"] else None
best_bleu4 = -1.0
best_model_dir = os.path.join(config["output_dir"], "best_model")
log_file = os.path.join(config["output_dir"], "training_log.csv")

with open(log_file, "w") as f:
    f.write("epoch,train_loss,val_loss,BLEU-1,BLEU-2,BLEU-3,BLEU-4,ROUGE-L,METEOR,CIDEr\n")

for epoch in range(1, config["epochs"] + 1):
    train_loss = train_one_epoch(epoch)
    val_loss, val_metrics, _, _, _ = evaluate_model(val_loader, "éªŒè¯")

    print(f"\nEpoch {epoch}/{config['epochs']}")
    print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}")
    print(f"éªŒè¯æŸå¤±: {val_loss:.4f}")
    for k, v in val_metrics.items():
        print(f"{k}: {v:.4f}")

    # å†™å…¥æ—¥å¿—
    with open(log_file, "a") as f:
        f.write(f"{epoch},{train_loss:.4f},{val_loss:.4f}")
        for k in ["BLEU-1","BLEU-2","BLEU-3","BLEU-4","ROUGE-L","METEOR","CIDEr"]:
            f.write(f",{val_metrics.get(k, float('nan')):.4f}")
        f.write("\n")

    # âœ… ä»…ä¿å­˜BLEU-4æœ€ä¼˜æ¨¡å‹
    if val_metrics.get("BLEU-4", -1.0) > best_bleu4:
        best_bleu4 = val_metrics["BLEU-4"]
        os.makedirs(best_model_dir, exist_ok=True)
        model.save_pretrained(best_model_dir)
        processor.save_pretrained(best_model_dir)
        print(f"ğŸŒŸ æœ€ä½³æ¨¡å‹æ›´æ–° (Epoch {epoch}, BLEU-4: {best_bleu4:.4f})")

print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {best_model_dir}")

# ================ 9. æµ‹è¯•é›†è¯„ä¼° ================
if test_loader:
    print("\n===== æµ‹è¯•é›†è¯„ä¼° =====")
    best_model = BlipForConditionalGeneration.from_pretrained(best_model_dir).to(config["device"])
    model = best_model
    test_results_path = os.path.join(config["output_dir"], "test_results.csv")
    test_loss, test_metrics, _, _, _ = evaluate_model(test_loader, "æµ‹è¯•", save_results_path=test_results_path)
    print("\næµ‹è¯•é›†æœ€ç»ˆæŒ‡æ ‡:")
    for k, v in test_metrics.items():
        print(f"{k}: {v:.4f}")

print(f"\nè®­ç»ƒå®Œæˆ! æ¨¡å‹ä¿å­˜äº: {config['output_dir']}")
